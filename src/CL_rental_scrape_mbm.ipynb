{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('melis': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "081b6216928d55ece203d92fdcd5214719477f63e022b6b86f3f62fef0361037"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "import dns\n",
    "import datetime\n",
    "from config import pg_username, pg_password\n",
    "from time import sleep\n",
    "import random\n",
    "import json\n",
    "\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = f'mongodb+srv://{pg_username}:{pg_password}@cluster0.4dt6k.mongodb.net/test?authSource=admin&replicaSet=Cluster0-shard-0&readPreference=primary&appname=MongoDB%20Compass&ssl=true'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.craigslist_db\n",
    "listings_collection = db.listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7278244211\n"
     ]
    }
   ],
   "source": [
    "for listing in listings_collection.find():\n",
    "    print(listing['data_id'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2662"
      ]
     },
     "metadata": {},
     "execution_count": 686
    }
   ],
   "source": [
    "listings_collection.find().count()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_listing(cl_result_row):\n",
    "    data_id = result.h3.a['data-id']\n",
    "    if listings_collection.find({'data_id': data_id}).count() == 0:\n",
    "        print(\"Insert new listing! \")\n",
    "        \n",
    "        listing_title = result.find('a', class_='result-title').text\n",
    "        listing_price = result.a.span.text\n",
    "        listing_link = result.a['href']\n",
    "        listing_datetime = result.time['datetime']\n",
    "        created_datetime = datetime.datetime.utcnow()\n",
    "        \n",
    "        # Run only if all fields are available\n",
    "        if (listing_title and listing_price and listing_link and listing_datetime and data_id and created_datetime):\n",
    "            # Print results\n",
    "            print('-------------')\n",
    "            print(data_id)\n",
    "            print(listing_title)\n",
    "            print(listing_price)\n",
    "            print(listing_link)\n",
    "            print(listing_datetime)        \n",
    "            print(created_datetime)\n",
    "\n",
    "            # Dictionary to be inserted as a MongoDB document\n",
    "            post = {\n",
    "                'data_id': data_id,\n",
    "                'created_datetime': created_datetime,\n",
    "                'listing_title': title,\n",
    "                'listing_price': price,\n",
    "                'listing_url': link,\n",
    "                'listing_date': listing_datetime\n",
    "                \n",
    "            }\n",
    "            listings_collection.insert_one(post)\n",
    "        else:\n",
    "            print(\"Listing missing values. Skip listing.\")\n",
    "    else: \n",
    "        print(f\"Listing {data_id} already exists, do not insert new. On to the next listing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved page one of results locally for temp solution to build out scripts/functions\n",
    "# filepath = os.path.join('..','resources','cl_sandiego_northcounty_apa.html')\n",
    "# with open(filepath, encoding='utf-8') as file:\n",
    "#     html = file.read()\n",
    "\n",
    "# soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'_id': ObjectId('60330e35566e11a3b7aedbf6'), 'data_id': '7278244211', 'created_datetime': datetime.datetime(2021, 2, 22, 1, 51, 49, 230000), 'listing_title': 'Dog Park, In-Unit Laundry, Extra storage', 'listing_price': '$2,095', 'listing_url': 'https://sandiego.craigslist.org/nsd/apa/d/carlsbad-dog-park-in-unit-laundry-extra/7278244211.html', 'listing_date': '2021-02-21 15:13', 'listing_addrcountry': 'US', 'listing_address': '3402 Calle Odessa', 'listing_addrlocality': 'Carlsbad', 'listing_addrregion': 'CA', 'listing_addrstreet': '3402 Calle Odessa', 'listing_addrzip': '92009', 'listing_attributes': ['cats are OK - purrr', 'dogs are OK - wooof', 'apartment', 'w/d in unit', 'no smoking', 'carport'], 'listing_availability': '', 'listing_bath': 1, 'listing_bed': '1', 'listing_bedbath': '1BR / 1Ba', 'listing_latitude': '33.077861', 'listing_longitude': '-117.234826', 'listing_petsallowed': 'True', 'listing_smokingallowed': 'False', 'listing_type': 'Apartment', 'listing_sqft': '679ft2'}\n"
     ]
    }
   ],
   "source": [
    "for listing in listings_collection.find():\n",
    "    print(listing)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2662"
      ]
     },
     "metadata": {},
     "execution_count": 689
    }
   ],
   "source": [
    "listings_collection.find().count()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_details(listing_url):\n",
    "    # URL of page to be scraped\n",
    "    url = listing_url\n",
    "\n",
    "    sleep(random.randint(1,3))\n",
    "    # Retrieve page with the requests module\n",
    "    response = requests.get(url)\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(response.text,'lxml')    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_listing_details(cl_result_details,data_id):   \n",
    "    # Examine the results, then determine element that contains sought info\n",
    "    # results are returned as an iterable list\n",
    "    result_details = cl_result_details.find_all('div', class_='mapAndAttrs')\n",
    "    \n",
    "    viewposting = cl_result_details.find_all('div', class_='viewposting')\n",
    "    listing_latitude = viewposting[0]['data-latitude']\n",
    "    listing_longitude = viewposting[0]['data-longitude']\n",
    "    \n",
    "    # mapaddress = cl_result_details.find_all('div', class_='mapaddress')\n",
    "    # listing_address = mapaddress[0].text\n",
    "    \n",
    "    attrgroups = cl_result_details.find_all('p', class_='attrgroup')\n",
    "    \n",
    "    listing_availability = ''\n",
    "    listing_sqft = ''\n",
    "\n",
    "    for attrgroup in attrgroups:\n",
    "        listing_attributes = []\n",
    "        attrspan = attrgroup.find_all('span')\n",
    "        for span in attrspan:\n",
    "            if ((span.text.lower().find('br') != -1) & (span.text.lower().find('ba') != -1)):\n",
    "                listing_bedbath = span.text                \n",
    "            elif span.text.lower().find('ft2') != -1:\n",
    "                listing_sqft = span.text\n",
    "            elif span.text.lower().find('available') != -1:\n",
    "                listing_availability = span.text\n",
    "            else: \n",
    "                listing_attributes.append(span.text)\n",
    "\n",
    "    listing_type = ''\n",
    "    listing_bed = ''\n",
    "    listing_bath = ''\n",
    "    listing_petsallowed = ''\n",
    "    listing_smokingallowed = ''\n",
    "\n",
    "    listing_addrcountry = ''\n",
    "    listing_addrlocality = ''\n",
    "    listing_addrregion = ''\n",
    "    listing_addrregion = ''\n",
    "    listing_addrzip = ''\n",
    "    listing_addrstreet = ''\n",
    "        \n",
    "    soup_scripts = cl_result_details.find_all('script',id='ld_posting_data')\n",
    "\n",
    "    # Getting dictionary\n",
    "    scripts_dict = json.loads(soup_scripts[0].contents[0].strip())\n",
    "\n",
    "    # Pretty Printing JSON string back\n",
    "    # print(json.dumps(scripts_dict, indent = 4, sort_keys=True))\n",
    "        \n",
    "    if '@type' in scripts_dict:\n",
    "        listing_type = scripts_dict['@type']\n",
    "    if 'numberOfBedrooms' in scripts_dict:\n",
    "        listing_bed = scripts_dict['numberOfBedrooms']\n",
    "    if 'numberOfBathroomsTotal' in scripts_dict:\n",
    "        listing_bath = scripts_dict['numberOfBathroomsTotal']\n",
    "    if 'petsAllowed' in scripts_dict:\n",
    "        listing_petsallowed = str(scripts_dict['petsAllowed'])\n",
    "    if 'smokingAllowed' in scripts_dict:\n",
    "        listing_smokingallowed = str(scripts_dict['smokingAllowed'])\n",
    "    \n",
    "\n",
    "    if 'address' in scripts_dict:\n",
    "        address_dict = scripts_dict['address']\n",
    "        if 'addressCountry' in address_dict:\n",
    "            listing_addrcountry = address_dict['addressCountry']\n",
    "        if 'addressLocality' in address_dict:\n",
    "            listing_addrlocality = address_dict['addressLocality']\n",
    "        if 'addressRegion' in address_dict:\n",
    "            listing_addrregion = address_dict['addressRegion']\n",
    "        if 'postalCode' in address_dict:\n",
    "            listing_addrzip = address_dict['postalCode']\n",
    "        if 'streetAddress' in address_dict:\n",
    "            listing_addrstreet = address_dict['streetAddress']\n",
    "        \n",
    "\n",
    "    print(data_id)\n",
    "    print(listing_latitude)\n",
    "    print(listing_longitude)    \n",
    "    print(listing_bedbath)\n",
    "    print(listing_sqft)\n",
    "    print(listing_availability)\n",
    "    print(listing_attributes)\n",
    "    print(listing_addrcountry)\n",
    "    print(listing_addrlocality)\n",
    "    print(listing_addrregion)\n",
    "    print(listing_addrzip)\n",
    "    print(listing_addrstreet)\n",
    "    print(listing_type)\n",
    "    print(listing_bed)\n",
    "    print(listing_bath)\n",
    "    print(listing_petsallowed)\n",
    "    print(listing_smokingallowed)\n",
    "    print('------------------------------')\n",
    "\n",
    "    doc = listings_collection.find_one_and_update(\n",
    "        {'data_id' : data_id},\n",
    "        {'$set':\n",
    "            {\n",
    "                'listing_latitude': listing_latitude,\n",
    "                'listing_longitude': listing_longitude,                \n",
    "                'listing_bedbath':listing_bedbath,\n",
    "                'listing_sqft':listing_sqft,\n",
    "                'listing_availability':listing_availability,\n",
    "                'listing_attributes':listing_attributes,\n",
    "                'listing_addrcountry':listing_addrcountry,\n",
    "                'listing_addrlocality':listing_addrlocality,\n",
    "                'listing_addrregion':listing_addrregion,\n",
    "                'listing_addrzip':listing_addrzip,\n",
    "                'listing_addrstreet':listing_addrstreet,\n",
    "                'listing_type':listing_type,\n",
    "                'listing_bed':listing_bed,\n",
    "                'listing_bath':listing_bath,\n",
    "                'listing_petsallowed':listing_petsallowed,\n",
    "                'listing_smokingallowed':listing_smokingallowed,                \n",
    "            }\n",
    "            \n",
    "        },upsert=True\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'_id': ObjectId('60330e42566e11a3b7aedc54'), 'data_id': '7280736862', 'created_datetime': datetime.datetime(2021, 2, 22, 1, 52, 2, 943000), 'listing_title': 'Strike While the Iron is Hot! 6-Weeks FREE!', 'listing_price': '$1,995', 'listing_url': 'https://sandiego.craigslist.org/nsd/apa/d/vista-strike-while-the-iron-is-hot/7280736862.html', 'listing_date': '2021-02-21 11:42', 'listing_address': '2051 Geneva St', 'listing_attributes': ['EV charging', 'cats are OK - purrr', 'dogs are OK - wooof', 'apartment', 'w/d in unit', 'no smoking', 'detached garage'], 'listing_availability': 'available now', 'listing_bedbath': '1BR / 1Ba', 'listing_latitude': '33.208926', 'listing_longitude': '-117.234635', 'listing_addrcountry': 'US', 'listing_addrlocality': 'Vista', 'listing_addrregion': 'CA', 'listing_addrstreet': '740 Paseo Buena Vista', 'listing_addrzip': '92085', 'listing_bath': 1, 'listing_bed': '1', 'listing_petsallowed': 'True', 'listing_smokingallowed': 'False', 'listing_type': 'Apartment', 'listing_sqft': '732ft2'}\n"
     ]
    }
   ],
   "source": [
    "find_result = listings_collection.find_one({'data_id': '7280736862'})\n",
    "print(find_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "\n",
      "\n",
      "[WDM] - Driver [C:\\Users\\melis\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings results\n",
    "# url_listings_northsd = 'https://sandiego.craigslist.org/search/nsd/apa'\n",
    "# url_listings_eastsd = 'https://sandiego.craigslist.org/search/esd/apa'\n",
    "# url_lisings_cityofsd = 'https://sandiego.craigslist.org/search/csd/apa'\n",
    "url_lisings_southsd = 'https://sandiego.craigslist.org/search/ssd/apa'\n",
    "browser.visit(url_lisings_southsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all pages\n",
    "for x in range(12):\n",
    "    # HTML object\n",
    "    html_listings = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup_listings = BeautifulSoup(html_listings, 'html.parser')\n",
    "    # Retrieve all elements that contain book information\n",
    "    soup_listings = BeautifulSoup(html_listings)\n",
    "\n",
    "    results = soup_listings.find_all('li', class_='result-row')\n",
    "\n",
    "    # Loop through returned results\n",
    "    for result in results:\n",
    "        try:\n",
    "            insert_listing(result)                                                          \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    try:\n",
    "        browser.links.find_by_partial_text('next').click()          \n",
    "    except:\n",
    "        print(\"Scraping Complete\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "\n",
      "\n",
      "[WDM] - Driver [C:\\Users\\melis\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "connect ECONNREFUSED 127.0.0.1:55291",
     "traceback": [
      "Error: connect ECONNREFUSED 127.0.0.1:55291",
      "at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1141:16)"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "\n",
    "for l in listings_collection.find():\n",
    "    \n",
    "    isNeedUpdate = False\n",
    "    try: \n",
    "        listing_address = l['listing_addrzip']\n",
    "    except:\n",
    "        isNeedUpdate = True\n",
    "\n",
    "    try: \n",
    "        listing_address = l['listing_sqft']\n",
    "    except:\n",
    "        isNeedUpdate = True\n",
    "\n",
    "    try: \n",
    "        listing_addrstreet = l['listing_addrstreet']\n",
    "        if (listing_addrstreet == '1510 S. MELROSE'):\n",
    "            isNeedUpdate = True  \n",
    "    except:\n",
    "        isNeedUpdate = True        \n",
    "\n",
    "    if isNeedUpdate == True:\n",
    "        data_id = l['data_id']\n",
    "        url_details = l['listing_url']\n",
    "        \n",
    "        print('Index ' + str(x) + ' Updating listing details data_id ' + data_id)\n",
    "\n",
    "        if (url_details != ''):\n",
    "            sleep(random.randint(1,3))\n",
    "            browser.visit(url_details)\n",
    "            html_details = browser.html\n",
    "\n",
    "            soup_details = BeautifulSoup(html_details)\n",
    "            \n",
    "            try:\n",
    "                insert_listing_details(soup_details, data_id)\n",
    "            except Exception as e:               \n",
    "                print(e)  \n",
    "            \n",
    "    else:\n",
    "        listing_address = ''\n",
    "    \n",
    "    x += 1\n",
    "    if x > 7952:            \n",
    "        print('Scrape Completed')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}